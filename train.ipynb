{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d83841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "from configuration import Configuration\n",
    "from configuration import CONSTANTS as C\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from nltk.translate.bleu_score import sentence_bleu,SmoothingFunction\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "from torch import cuda\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92df0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "    \"\"\"\n",
    "    Creating a custom dataset for reading the dataset and \n",
    "    loading it into the dataloader to pass it to the neural network for finetuning the model\n",
    "    \"\"\"    \n",
    "    def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        self.target_text = self.data[target_text]\n",
    "        self.source_text = self.data[source_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "        #cleaning data so as to ensure data is in string type\n",
    "        source_text = ' '.join(source_text.split())\n",
    "        target_text = ' '.join(target_text.split())\n",
    "        source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def create_model_dir(experiment_main_dir, experiment_id, model_summary):\n",
    "    \"\"\"\n",
    "    Create a new model directory.\n",
    "    :param experiment_main_dir: Where all experiments are stored.\n",
    "    :param experiment_id: The ID of this experiment.\n",
    "    :param model_summary: A summary string of the model.\n",
    "    :return: A directory where we can store model logs. Raises an exception if the model directory already exists.\n",
    "    \"\"\"\n",
    "    model_name = \"{}-{}\".format(experiment_id, model_summary)\n",
    "    model_dir = os.path.join(experiment_main_dir, model_name)\n",
    "    if os.path.exists(model_dir):\n",
    "        raise ValueError(\"Model directory already exists {}\".format(model_dir))\n",
    "    os.makedirs(model_dir)\n",
    "    return model_dir\n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer,writer,global_step,records,model_dir):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "    checkpoint_file = os.path.join(model_dir, 'model.pth')\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"loss\", loss, global_step)\n",
    "        \n",
    "        \n",
    "        ### measure bleu\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "          input_ids = ids,\n",
    "          attention_mask = mask, \n",
    "          max_length=150, \n",
    "          num_beams=2,\n",
    "          repetition_penalty=2.5, \n",
    "          length_penalty=1.0, \n",
    "          early_stopping=True\n",
    "          )\n",
    "        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in generated_ids]\n",
    "        target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=False)for t in y]\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(target)\n",
    "\n",
    "        temp_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "\n",
    "        val=records.rename(columns={'distractor':'Actual Text'})\n",
    "\n",
    "        gen_dist=val.merge(temp_df,on=['Actual Text']).loc[:,['text','Generated Text']]\n",
    "\n",
    "        distractors=val.groupby(['text']).agg({ 'Actual Text': lambda x: list(x)}).reset_index()\n",
    "\n",
    "        dist_compare=distractors.merge(gen_dist,on=['text'])\n",
    "        aa=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 1, 0)),axis=1)\n",
    "        dist_compare=dist_compare.assign(bleu=aa)\n",
    "        #dist_compare=dist_compare.assign(bleu=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 1, 0)),axis=1))\n",
    "        bleu_3=dist_compare.bleu.mean()\n",
    "        torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'global_step': global_step,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, checkpoint_file)\n",
    "        path = os.path.join(model_dir, \"model_files\")\n",
    "        model.save_pretrained(path)\n",
    "        tokenizer.save_pretrained(path)\n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "        writer.add_scalar(\"bleu3\", bleu_3, global_step)\n",
    "        \n",
    "        \n",
    "        global_step += 1\n",
    "    return (global_step,model)\n",
    "\n",
    "\n",
    "def validate(epoch, tokenizer, model, device, loader,writer):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to evaluate model for predictions\n",
    "\n",
    "    \"\"\"\n",
    "    global_step = 0\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    c=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            c=c+1\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              num_beams=2,\n",
    "              repetition_penalty=2.5, \n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "            if c%100==0:\n",
    "                print(c)\n",
    "        temp_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "\n",
    "        val=records.rename(columns={'distractor':'Actual Text'})\n",
    "\n",
    "        gen_dist=val.merge(temp_df,on=['Actual Text']).loc[:,['text','Generated Text']]\n",
    "\n",
    "        distractors=val.groupby(['text']).agg({ 'Actual Text': lambda x: list(x.str.split())}).reset_index()\n",
    "\n",
    "        dist_compare=distractors.merge(gen_dist,on=['text'])\n",
    "        dist_compare['Generated Text']=dist_compare['Generated Text'].str.split()\n",
    "        aa=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 1, 0, 0),smoothing_function=SmoothingFunction().method1),axis=1)\n",
    "        dist_compare=dist_compare.assign(bleu=aa)\n",
    "        bleu_2=dist_compare.bleu.mean()\n",
    "        writer.add_scalar(\"bleu2_val\", bleu_2, 1)\n",
    "            \n",
    "            \n",
    "            #writer.add_scalar(\"loss_validation\", float(loss.detach().numpy()), global_step)\n",
    "            #global_step += 1\n",
    "    return predictions, actuals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620e44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"t5-small\",             # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":4,          # training batch size\n",
    "    \"VALID_BATCH_SIZE\":4,          # validation batch size\n",
    "    \"TRAIN_EPOCHS\":2,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":1800,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":200,   # max length of target text\n",
    "    \"SEED\": 42                     # set seed for reproducibility \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "source_text='text'\n",
    "target_text='distractor'\n",
    "model_params=model_params\n",
    "\n",
    "with open(os.path.join(C.DATA_DIR, \"distractor/race_train_original.json\"), 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "content=content.replace('\\n',',')\n",
    "content='['+content[:-1]+']'\n",
    "records = json.loads(content)\n",
    "records=pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d66616",
   "metadata": {},
   "outputs": [],
   "source": [
    "records=pd.read_csv(os.path.join(C.DATA_DIR, \"distractor/RACE_dev_new.csv\"))\n",
    "\n",
    "records=records[~records.answer_text.str.contains(\";\")]\n",
    "\n",
    "records.article=records.article.str.split()\n",
    "records.question=records.question.str.split()\n",
    "records.answer_text=records.answer_text.str.split()\n",
    "records.distractor=records.distractor.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16bce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lohri is an agricultural festival, filled with...</td>\n",
       "      <td>All of following are true about Dulha Bhatti E...</td>\n",
       "      <td>he was the actor who played Robin Hood</td>\n",
       "      <td>he often helped poor people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lohri is an agricultural festival, filled with...</td>\n",
       "      <td>All of following are true about Dulha Bhatti E...</td>\n",
       "      <td>he was the actor who played Robin Hood</td>\n",
       "      <td>he was a different kind of thief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lohri is an agricultural festival, filled with...</td>\n",
       "      <td>All of following are true about Dulha Bhatti E...</td>\n",
       "      <td>he was the actor who played Robin Hood</td>\n",
       "      <td>he is respected by people in Punjab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lohri is an agricultural festival, filled with...</td>\n",
       "      <td>We know from the passage that Lohri   _   .</td>\n",
       "      <td>has the same name as the munchies that the chi...</td>\n",
       "      <td>has nothing to do with agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lohri is an agricultural festival, filled with...</td>\n",
       "      <td>We know from the passage that Lohri   _   .</td>\n",
       "      <td>has the same name as the munchies that the chi...</td>\n",
       "      <td>is celebrated both indoors and outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14653</th>\n",
       "      <td>October 1st, 2011\\nDear Ann,\\nI hope that you ...</td>\n",
       "      <td>Linda lives in   _   .</td>\n",
       "      <td>a small town</td>\n",
       "      <td>a big town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14654</th>\n",
       "      <td>October 1st, 2011\\nDear Ann,\\nI hope that you ...</td>\n",
       "      <td>Linda lives in   _   .</td>\n",
       "      <td>a small town</td>\n",
       "      <td>a country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14655</th>\n",
       "      <td>October 1st, 2011\\nDear Ann,\\nI hope that you ...</td>\n",
       "      <td>Ann and her children are going to Linda's home...</td>\n",
       "      <td>by train</td>\n",
       "      <td>by bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14656</th>\n",
       "      <td>October 1st, 2011\\nDear Ann,\\nI hope that you ...</td>\n",
       "      <td>Ann and her children are going to Linda's home...</td>\n",
       "      <td>by train</td>\n",
       "      <td>by car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14657</th>\n",
       "      <td>October 1st, 2011\\nDear Ann,\\nI hope that you ...</td>\n",
       "      <td>Ann and her children are going to Linda's home...</td>\n",
       "      <td>by train</td>\n",
       "      <td>on foot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14628 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      Lohri is an agricultural festival, filled with...   \n",
       "1      Lohri is an agricultural festival, filled with...   \n",
       "2      Lohri is an agricultural festival, filled with...   \n",
       "3      Lohri is an agricultural festival, filled with...   \n",
       "4      Lohri is an agricultural festival, filled with...   \n",
       "...                                                  ...   \n",
       "14653  October 1st, 2011\\nDear Ann,\\nI hope that you ...   \n",
       "14654  October 1st, 2011\\nDear Ann,\\nI hope that you ...   \n",
       "14655  October 1st, 2011\\nDear Ann,\\nI hope that you ...   \n",
       "14656  October 1st, 2011\\nDear Ann,\\nI hope that you ...   \n",
       "14657  October 1st, 2011\\nDear Ann,\\nI hope that you ...   \n",
       "\n",
       "                                                question  \\\n",
       "0      All of following are true about Dulha Bhatti E...   \n",
       "1      All of following are true about Dulha Bhatti E...   \n",
       "2      All of following are true about Dulha Bhatti E...   \n",
       "3            We know from the passage that Lohri   _   .   \n",
       "4            We know from the passage that Lohri   _   .   \n",
       "...                                                  ...   \n",
       "14653                             Linda lives in   _   .   \n",
       "14654                             Linda lives in   _   .   \n",
       "14655  Ann and her children are going to Linda's home...   \n",
       "14656  Ann and her children are going to Linda's home...   \n",
       "14657  Ann and her children are going to Linda's home...   \n",
       "\n",
       "                                             answer_text  \\\n",
       "0                 he was the actor who played Robin Hood   \n",
       "1                 he was the actor who played Robin Hood   \n",
       "2                 he was the actor who played Robin Hood   \n",
       "3      has the same name as the munchies that the chi...   \n",
       "4      has the same name as the munchies that the chi...   \n",
       "...                                                  ...   \n",
       "14653                                       a small town   \n",
       "14654                                       a small town   \n",
       "14655                                           by train   \n",
       "14656                                           by train   \n",
       "14657                                           by train   \n",
       "\n",
       "                                    distractor  \n",
       "0                  he often helped poor people  \n",
       "1             he was a different kind of thief  \n",
       "2          he is respected by people in Punjab  \n",
       "3           has nothing to do with agriculture  \n",
       "4      is celebrated both indoors and outdoors  \n",
       "...                                        ...  \n",
       "14653                               a big town  \n",
       "14654                                a country  \n",
       "14655                                   by bus  \n",
       "14656                                   by car  \n",
       "14657                                  on foot  \n",
       "\n",
       "[14628 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records2=records2[~records2.answer_text.str.contains(\";\")]\n",
    "\n",
    "records2.article=records2.article.str.split()\n",
    "records2.question=records2.question.str.split()\n",
    "records2.answer_text=records2.answer_text.str.split()\n",
    "records2.distractor=records2.distractor.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0822a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Lohri, is, an, agricultural, festival,, fille...</td>\n",
       "      <td>[All, of, following, are, true, about, Dulha, ...</td>\n",
       "      <td>[he, was, the, actor, who, played, Robin, Hood]</td>\n",
       "      <td>[he, often, helped, poor, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Lohri, is, an, agricultural, festival,, fille...</td>\n",
       "      <td>[All, of, following, are, true, about, Dulha, ...</td>\n",
       "      <td>[he, was, the, actor, who, played, Robin, Hood]</td>\n",
       "      <td>[he, was, a, different, kind, of, thief]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Lohri, is, an, agricultural, festival,, fille...</td>\n",
       "      <td>[All, of, following, are, true, about, Dulha, ...</td>\n",
       "      <td>[he, was, the, actor, who, played, Robin, Hood]</td>\n",
       "      <td>[he, is, respected, by, people, in, Punjab]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Lohri, is, an, agricultural, festival,, fille...</td>\n",
       "      <td>[We, know, from, the, passage, that, Lohri, _, .]</td>\n",
       "      <td>[has, the, same, name, as, the, munchies, that...</td>\n",
       "      <td>[has, nothing, to, do, with, agriculture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Lohri, is, an, agricultural, festival,, fille...</td>\n",
       "      <td>[We, know, from, the, passage, that, Lohri, _, .]</td>\n",
       "      <td>[has, the, same, name, as, the, munchies, that...</td>\n",
       "      <td>[is, celebrated, both, indoors, and, outdoors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14656</th>\n",
       "      <td>[October, 1st,, 2011, Dear, Ann,, I, hope, tha...</td>\n",
       "      <td>[Ann, and, her, children, are, going, to, Lind...</td>\n",
       "      <td>[by, train]</td>\n",
       "      <td>[by, car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14657</th>\n",
       "      <td>[October, 1st,, 2011, Dear, Ann,, I, hope, tha...</td>\n",
       "      <td>[Ann, and, her, children, are, going, to, Lind...</td>\n",
       "      <td>[by, train]</td>\n",
       "      <td>[on, foot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14658</th>\n",
       "      <td>[October, 1st,, 2011, Dear, Ann,, I, hope, tha...</td>\n",
       "      <td>[From, the, letter, we, know, that, Tom, loves...</td>\n",
       "      <td>[sports;, animals]</td>\n",
       "      <td>[music;, animals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>[October, 1st,, 2011, Dear, Ann,, I, hope, tha...</td>\n",
       "      <td>[From, the, letter, we, know, that, Tom, loves...</td>\n",
       "      <td>[sports;, animals]</td>\n",
       "      <td>[sports;, dancing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14660</th>\n",
       "      <td>[October, 1st,, 2011, Dear, Ann,, I, hope, tha...</td>\n",
       "      <td>[From, the, letter, we, know, that, Tom, loves...</td>\n",
       "      <td>[sports;, animals]</td>\n",
       "      <td>[animals;, sports]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14661 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      [Lohri, is, an, agricultural, festival,, fille...   \n",
       "1      [Lohri, is, an, agricultural, festival,, fille...   \n",
       "2      [Lohri, is, an, agricultural, festival,, fille...   \n",
       "3      [Lohri, is, an, agricultural, festival,, fille...   \n",
       "4      [Lohri, is, an, agricultural, festival,, fille...   \n",
       "...                                                  ...   \n",
       "14656  [October, 1st,, 2011, Dear, Ann,, I, hope, tha...   \n",
       "14657  [October, 1st,, 2011, Dear, Ann,, I, hope, tha...   \n",
       "14658  [October, 1st,, 2011, Dear, Ann,, I, hope, tha...   \n",
       "14659  [October, 1st,, 2011, Dear, Ann,, I, hope, tha...   \n",
       "14660  [October, 1st,, 2011, Dear, Ann,, I, hope, tha...   \n",
       "\n",
       "                                                question  \\\n",
       "0      [All, of, following, are, true, about, Dulha, ...   \n",
       "1      [All, of, following, are, true, about, Dulha, ...   \n",
       "2      [All, of, following, are, true, about, Dulha, ...   \n",
       "3      [We, know, from, the, passage, that, Lohri, _, .]   \n",
       "4      [We, know, from, the, passage, that, Lohri, _, .]   \n",
       "...                                                  ...   \n",
       "14656  [Ann, and, her, children, are, going, to, Lind...   \n",
       "14657  [Ann, and, her, children, are, going, to, Lind...   \n",
       "14658  [From, the, letter, we, know, that, Tom, loves...   \n",
       "14659  [From, the, letter, we, know, that, Tom, loves...   \n",
       "14660  [From, the, letter, we, know, that, Tom, loves...   \n",
       "\n",
       "                                             answer_text  \\\n",
       "0        [he, was, the, actor, who, played, Robin, Hood]   \n",
       "1        [he, was, the, actor, who, played, Robin, Hood]   \n",
       "2        [he, was, the, actor, who, played, Robin, Hood]   \n",
       "3      [has, the, same, name, as, the, munchies, that...   \n",
       "4      [has, the, same, name, as, the, munchies, that...   \n",
       "...                                                  ...   \n",
       "14656                                        [by, train]   \n",
       "14657                                        [by, train]   \n",
       "14658                                 [sports;, animals]   \n",
       "14659                                 [sports;, animals]   \n",
       "14660                                 [sports;, animals]   \n",
       "\n",
       "                                           distractor  \n",
       "0                   [he, often, helped, poor, people]  \n",
       "1            [he, was, a, different, kind, of, thief]  \n",
       "2         [he, is, respected, by, people, in, Punjab]  \n",
       "3           [has, nothing, to, do, with, agriculture]  \n",
       "4      [is, celebrated, both, indoors, and, outdoors]  \n",
       "...                                               ...  \n",
       "14656                                       [by, car]  \n",
       "14657                                      [on, foot]  \n",
       "14658                               [music;, animals]  \n",
       "14659                              [sports;, dancing]  \n",
       "14660                              [animals;, sports]  \n",
       "\n",
       "[14661 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3833330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    model_params={\n",
    "        \"MODEL\":\"t5-small\",             # model_type: t5-base/t5-large\n",
    "        \"TRAIN_BATCH_SIZE\":4,          # training batch size\n",
    "        \"VALID_BATCH_SIZE\":4,          # validation batch size\n",
    "        \"TRAIN_EPOCHS\":2,              # number of training epochs\n",
    "        \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "        \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "        \"MAX_SOURCE_TEXT_LENGTH\":1800,  # max length of source text\n",
    "        \"MAX_TARGET_TEXT_LENGTH\":200,   # max length of target text\n",
    "        \"SEED\": 42                     # set seed for reproducibility \n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    source_text='text'\n",
    "    target_text='distractor'\n",
    "    model_params=model_params\n",
    "\n",
    "    with open(os.path.join(C.DATA_DIR, \"distractor/race_train_original.json\"), 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "    content=content.replace('\\n',',')\n",
    "    content='['+content[:-1]+']'\n",
    "    records = json.loads(content)\n",
    "    records=pd.DataFrame(records)\n",
    "    \n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(C.DEVICE)\n",
    "\n",
    "    ## format the input\n",
    "    records=records.assign(question=records.question.str.join(' '))\n",
    "    records=records.assign(distractor=records.distractor.str.join(' '))\n",
    "    records=records.assign(article=records.article.str.join(' '))\n",
    "    records=records.assign(answer_text=records.answer_text.str.join(' '))\n",
    "    records=records.loc[:,['article','question','answer_text','distractor']]\n",
    "    records=records.assign(text=\"distraction passage: \"+records.article+\" question: \"+records.question+\" answer: \"+records.answer_text)\n",
    "    records=records.loc[:,['text','distractor']]\n",
    "\n",
    "    with open(os.path.join(C.DATA_DIR, \"distractor/race_dev_original.json\"), 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "    content=content.replace('\\n',',')\n",
    "    content='['+content[:-1]+']'\n",
    "    records_test = json.loads(content)\n",
    "    records_test=pd.DataFrame(records_test)\n",
    "\n",
    "    ## format the input\n",
    "    records_test=records_test.assign(question=records_test.question.str.join(' '))\n",
    "    records_test=records_test.assign(distractor=records_test.distractor.str.join(' '))\n",
    "    records_test=records_test.assign(article=records_test.article.str.join(' '))\n",
    "    records_test=records_test.assign(answer_text=records_test.answer_text.str.join(' '))\n",
    "    records_test=records_test.loc[:,['article','question','answer_text','distractor']]\n",
    "    records_test=records_test.assign(text=\"distraction passage: \"+records_test.article+\" question: \"+records_test.question+\" answer: \"+records_test.answer_text)\n",
    "    records_test=records_test.loc[:,['text','distractor']]\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "    val_dataset=records_test\n",
    "    train_dataset = records\n",
    "\n",
    "\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "    val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "    val_params = {\n",
    "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "      'shuffle': False,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "    \n",
    "    # Create Tensorboard logger.\n",
    "    experiment_id = int(time.time())\n",
    "    experiment_name = \"name\"\n",
    "    model_dir = create_model_dir(os.path.join(C.DATA_DIR, \"experiments/\"), experiment_id, experiment_name)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'w') as fp:\n",
    "        json.dump(model_params, fp)\n",
    "    global_step = 0\n",
    "    writer = SummaryWriter(os.path.join(model_dir, 'logs'))\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        global_step,model=train(epoch, tokenizer, model, C.DEVICE, training_loader, optimizer,writer,global_step,records)\n",
    "        print(epoch)\n",
    "    #Saving the model after training\n",
    "    path = os.path.join(model_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "    # evaluating test dataset\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, C.DEVICE, val_loader,writer)\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv(os.path.join(model_dir, 'predictions.csv'),index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa9f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"t5-small\",             # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":2,          # training batch size\n",
    "    \"VALID_BATCH_SIZE\":2,          # validation batch size\n",
    "    \"TRAIN_EPOCHS\":1,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":900,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":200,   # max length of target text\n",
    "    \"SEED\": 42                     # set seed for reproducibility \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "source_text='text'\n",
    "target_text='distractor'\n",
    "model_params=model_params\n",
    "\n",
    "with open(os.path.join(C.DATA_DIR, \"distractor/race_train_original.json\"), 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "content=content.replace('\\n',',')\n",
    "content='['+content[:-1]+']'\n",
    "records = json.loads(content)\n",
    "records=pd.DataFrame(records)\n",
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
    "np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# tokenzier for encoding the text\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "model = model.to(C.DEVICE)\n",
    "\n",
    "## format the input\n",
    "records=records.assign(question=records.question.str.join(' '))\n",
    "records=records.assign(distractor=records.distractor.str.join(' '))\n",
    "records=records.assign(article=records.article.str.join(' '))\n",
    "records=records.assign(answer_text=records.answer_text.str.join(' '))\n",
    "records=records.loc[:,['article','question','answer_text','distractor']]\n",
    "records=records.assign(text=\"dist q: \"+records.question+\" a: \"+records.answer_text+\" p: \"+records.article)\n",
    "records=records.loc[:,['text','distractor']]\n",
    "\n",
    "\n",
    "with open(os.path.join(C.DATA_DIR, \"distractor/race_dev_original.json\"), 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "content=content.replace('\\n',',')\n",
    "content='['+content[:-1]+']'\n",
    "records_test = json.loads(content)\n",
    "records_test=pd.DataFrame(records_test)\n",
    "\n",
    "## format the input\n",
    "records_test=records_test.assign(question=records_test.question.str.join(' '))\n",
    "records_test=records_test.assign(distractor=records_test.distractor.str.join(' '))\n",
    "records_test=records_test.assign(article=records_test.article.str.join(' '))\n",
    "records_test=records_test.assign(answer_text=records_test.answer_text.str.join(' '))\n",
    "records_test=records_test.loc[:,['article','question','answer_text','distractor']]\n",
    "records_test=records_test.assign(text=\"dist q: \"+records_test.question+\" a: \"+records_test.answer_text+\" p: \"+records_test.article)\n",
    "records_test=records_test.loc[:,['text','distractor']]\n",
    "\n",
    "\n",
    "\n",
    "# Creation of Dataset and Dataloader\n",
    "# Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "#train_size = 0.8\n",
    "#train_dataset=records.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
    "val_dataset=records_test\n",
    "train_dataset = records\n",
    "\n",
    "\n",
    "\n",
    "# Creating the Training and Validation dataset for further creation of Dataloader\n",
    "training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "\n",
    "\n",
    "# Defining the parameters for creation of dataloaders\n",
    "train_params = {\n",
    "  'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "  'shuffle': True,\n",
    "  'num_workers': 0\n",
    "  }\n",
    "\n",
    "\n",
    "val_params = {\n",
    "  'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "  'shuffle': False,\n",
    "  'num_workers': 0\n",
    "  }\n",
    "\n",
    "\n",
    "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "global_step = 0\n",
    "# Create Tensorboard logger.\n",
    "experiment_id = int(time.time())\n",
    "experiment_name = \"name\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc1689e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dist q: What can we learn about cyber - beggin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dist q: What 's special when Bill Clinton was ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist q: This story is about a man a: who was n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist q: In what way are men different from ani...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dist q: Which is NOT the reason why people may...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>dist q: Why did Mary bring a skeleton home ? a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>dist q: These rare butterflies usually live in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>dist q: What do Lucy and Lily usually do on Sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>dist q: Why were those four presidents chosen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>dist q: What happened to Adam on Thursday Octo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  text\n",
       "0     dist q: What can we learn about cyber - beggin...     3\n",
       "1     dist q: What 's special when Bill Clinton was ...     3\n",
       "2     dist q: This story is about a man a: who was n...     3\n",
       "3     dist q: In what way are men different from ani...     3\n",
       "4     dist q: Which is NOT the reason why people may...     3\n",
       "...                                                 ...   ...\n",
       "6803  dist q: Why did Mary bring a skeleton home ? a...     1\n",
       "6804  dist q: These rare butterflies usually live in...     1\n",
       "6805  dist q: What do Lucy and Lily usually do on Sa...     1\n",
       "6806  dist q: Why were those four presidents chosen ...     1\n",
       "6807  dist q: What happened to Adam on Thursday Octo...     1\n",
       "\n",
       "[6808 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_test.text.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = create_model_dir(os.path.join(C.DATA_DIR, \"experiments/\"), experiment_id, experiment_name)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(os.path.join(model_dir, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1db9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1622184941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-24c56a0dc253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TRAIN_EPOCHS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ddc9a9b4c25f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, tokenizer, model, device, loader, optimizer, writer, global_step, records, model_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m           \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m           \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m           \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m           )\n\u001b[1;32m     91\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m             )\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m             )\n\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         )\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m                 )\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         )\n\u001b[1;32m    646\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_key_value_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"train\",experiment_id)\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "    global_step,model=train(epoch, tokenizer, model, C.DEVICE, training_loader, optimizer,writer,global_step,records,model_dir)\n",
    "    print(epoch)\n",
    "    \n",
    "#Saving the model after training\n",
    "path = os.path.join(model_dir, \"model_files\")\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "# evaluating test dataset\n",
    "for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, C.DEVICE, val_loader,writer)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "    final_df.to_csv(os.path.join(model_dir, 'predictions.csv'),index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eafb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_dir(experiment_dir, model_id):\n",
    "    \"\"\"Return the directory in `experiment_dir` that contains the given `model_id` string.\"\"\"\n",
    "    model_dir = glob.glob(os.path.join(experiment_dir, str(model_id) + \"-*\"), recursive=False)\n",
    "    return None if len(model_dir) == 0 else model_dir[0]\n",
    "\n",
    "def get_model_config(model_id):\n",
    "    model_id = model_id\n",
    "    model_dir = get_model_dir(os.path.join(C.DATA_DIR, \"experiments/\"), model_id)\n",
    "    model_config = Configuration.from_json(os.path.join(model_dir, 'config.json'))\n",
    "    return model_config, model_dir\n",
    "\n",
    "def load_model(model_id):\n",
    "    model_config, model_dir = get_model_config(model_id)\n",
    "    path = os.path.join(model_dir, \"model_files\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(path)\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(path)\n",
    "\n",
    "    model.to(C.DEVICE)\n",
    "\n",
    "    return model,tokenizer, model_config, model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b0e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,tokenizer, model_config, model_dir = load_model(1625497725)\n",
    "#1625497725\n",
    "#1625347324\n",
    "#1622295933\n",
    "#1622203727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1658a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vars(model_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b48579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"LAMBDA\": 0.3,\\n  \"LEARNING_RATE\": 0.0001,\\n  \"MAX_ANSWER_LENGTH\": 900,\\n  \"MAX_SOURCE_TEXT_LENGTH\": 900,\\n  \"MAX_TARGET_TEXT_LENGTH\": 901,\\n  \"MODEL\": \"t5-small\",\\n  \"SEED\": 42,\\n  \"TRAIN_BATCH_SIZE\": 2,\\n  \"TRAIN_EPOCHS\": 2,\\n  \"VALID_BATCH_SIZE\": 2,\\n  \"VAL_EPOCHS\": 1\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(vars(model_config), indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e49f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df55310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join(model_dir, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb3d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1b9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x2af1bfd3ca50>\n"
     ]
    }
   ],
   "source": [
    "print(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36c33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset=val_dataset.assign(distractor='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413f50e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>distractor</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dist q: McCulloch and his group used_in their ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dist q: McCulloch and his group used_in their ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist q: McCulloch and his group used_in their ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist q: We can infer from the passage that_. a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dist q: We can infer from the passage that_. a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>dist q: What is probably the best title for th...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16128</th>\n",
       "      <td>dist q: How do the shoes know that your should...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16129</th>\n",
       "      <td>dist q: How did Grace regain her eyesight ? a:...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16130</th>\n",
       "      <td>dist q: In what way can the surveillance camer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16131</th>\n",
       "      <td>dist q: What 's the best title for the passage...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16132 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text distractor answer\n",
       "0      dist q: McCulloch and his group used_in their ...                  \n",
       "1      dist q: McCulloch and his group used_in their ...                  \n",
       "2      dist q: McCulloch and his group used_in their ...                  \n",
       "3      dist q: We can infer from the passage that_. a...                  \n",
       "4      dist q: We can infer from the passage that_. a...                  \n",
       "...                                                  ...        ...    ...\n",
       "16127  dist q: What is probably the best title for th...                  \n",
       "16128  dist q: How do the shoes know that your should...                  \n",
       "16129  dist q: How did Grace regain her eyesight ? a:...                  \n",
       "16130  dist q: In what way can the surveillance camer...                  \n",
       "16131  dist q: What 's the best title for the passage...                  \n",
       "\n",
       "[16132 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdfba18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-337a56736ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VAL_EPOCHS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Generated Text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Actual Text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4771e7df93cb>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(epoch, tokenizer, model, device, loader, writer)\u001b[0m\n\u001b[1;32m    152\u001b[0m               \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m               \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m               \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m               )\n\u001b[1;32m    156\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;31m# add encoder_outputs to model_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_encoder_decoder_kwargs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0;31m# set input_ids as decoder_input_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, input_ids, model_kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0margument\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             }\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m                 )\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         )\n\u001b[1;32m    646\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_key_value_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# get query states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# get key/value states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib64/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, C.DEVICE, val_loader,writer)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "    final_df.to_csv(os.path.join(model_dir, 'predictions.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6968c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_csv(os.path.join(model_dir, 'predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1eee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25bc9278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu1</th>\n",
       "      <th>bleu2</th>\n",
       "      <th>bleu3</th>\n",
       "      <th>bleu4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num distractor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.252257</td>\n",
       "      <td>0.086770</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>0.036370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0.032212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218782</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>0.036209</td>\n",
       "      <td>0.027996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bleu1     bleu2     bleu3     bleu4\n",
       "Num distractor                                        \n",
       "1               0.252257  0.086770  0.048733  0.036370\n",
       "2               0.250600  0.080159  0.042729  0.032212\n",
       "3               0.218782  0.068267  0.036209  0.027996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby(['Num distractor']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff21de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_test_fil=records_test[~records_test.text.isin(records.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2a0cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dist q: McCulloch and his group used_in their research . a: 5 dogs and 169 people p: Dogs have long been used to find explosives and drugs . Now , a new study shows that man \\'s best friend can also help to find lung and breast cancer , researchers report in integrative Cancer Therapies . The findings show that trained ordinary household dogs can detect early -- stage lung and breast cancers by smelling the breath samples of patients . Researchers have found that cancer cells send out molecules different from those of healthy ones , and that might be sensed by smell by the highly sensitive dog \\'s nose . For the study , five dogs were trained by a professional instructor to respond differently to breath samples of healthy and cancer patients.\"The dogs learned to sit or lie down in front of cancer patient samples and to ignore control samples through the method of food reward , \" McCulloch explained . After a period of training , researchers tested the animals\\'ability to distinguish cancer patients from controls . The animals were given breath samples from 55 patients with lung cancer,3 1 with breast cancer and 83 healthy controls who were not included in the original training period . McCulloch \\'s group found that the dogs were able to correctly distinguish the breath samples of cancer patients from those of the control subjects in about 90 percent of the cases . The dogs were also able to detecting early - stage lung and breast cancers . \" These results show that there is hope for early detection,\"McCulloch said . The re - searches are planning to conduct further studies on the breath composition of cancer patients to possibly design an electronic device that can do the dogs\\'job.\"A dog \\'s nose is so powerful it can detect odors 10 000 to 100 000 times better than a human nose can . I hope people will be interested in doing this research,\"McCulloch added,\"It shows that there is definitely something out there . \"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_test[~records_test.text.isin(records.text)].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "903845fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, distractor]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[records.text=='dist q: McCulloch and his group used_in their research . a: 5 dogs and 169 people p: Dogs have long been used to find explosives and drugs . Now , a new study shows that man \\'s best friend can also help to find lung and breast cancer , researchers report in integrative Cancer Therapies . The findings show that trained ordinary household dogs can detect early -- stage lung and breast cancers by smelling the breath samples of patients . Researchers have found that cancer cells send out molecules different from those of healthy ones , and that might be sensed by smell by the highly sensitive dog \\'s nose . For the study , five dogs were trained by a professional instructor to respond differently to breath samples of healthy and cancer patients.\"The dogs learned to sit or lie down in front of cancer patient samples and to ignore control samples through the method of food reward , \" McCulloch explained . After a period of training , researchers tested the animals\\'ability to distinguish cancer patients from controls . The animals were given breath samples from 55 patients with lung cancer,3 1 with breast cancer and 83 healthy controls who were not included in the original training period . McCulloch \\'s group found that the dogs were able to correctly distinguish the breath samples of cancer patients from those of the control subjects in about 90 percent of the cases . The dogs were also able to detecting early - stage lung and breast cancers . \" These results show that there is hope for early detection,\"McCulloch said . The re - searches are planning to conduct further studies on the breath composition of cancer patients to possibly design an electronic device that can do the dogs\\'job.\"A dog \\'s nose is so powerful it can detect odors 10 000 to 100 000 times better than a human nose can . I hope people will be interested in doing this research,\"McCulloch added,\"It shows that there is definitely something out there . \"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc772f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = final_df\n",
    "\n",
    "val=records_test_fil.rename(columns={'distractor':'Actual Text'})\n",
    "\n",
    "gen_dist=val.merge(temp_df,on=['Actual Text']).loc[:,['text','Generated Text']].drop_duplicates()\n",
    "\n",
    "distractors=val.groupby(['text']).agg({ 'Actual Text': lambda x: list(x.str.split())}).reset_index()\n",
    "\n",
    "dist_compare=distractors.merge(gen_dist,on=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7876f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_compare['Generated Text']=dist_compare['Generated Text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca08a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(1, 0, 0, 0),smoothing_function=SmoothingFunction().method1),axis=1)\n",
    "b2=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 1, 0, 0),smoothing_function=SmoothingFunction().method1),axis=1)\n",
    "b3=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 1, 0),smoothing_function=SmoothingFunction().method1),axis=1)\n",
    "b4=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 0, 1),smoothing_function=SmoothingFunction().method1),axis=1)\n",
    "dist_compare=dist_compare.assign(bleu1=b1)\n",
    "dist_compare=dist_compare.assign(bleu2=b2)\n",
    "dist_compare=dist_compare.assign(bleu3=b3)\n",
    "dist_compare=dist_compare.assign(bleu4=b4)\n",
    "#dist_compare=dist_compare.assign(bleu=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 1, 0)),axis=1))\n",
    "bleu_1=dist_compare.bleu1.mean()\n",
    "bleu_2=dist_compare.bleu2.mean()\n",
    "bleu_3=dist_compare.bleu3.mean()\n",
    "bleu_4=dist_compare.bleu4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91598d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07887480099137983"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c749acd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dist q: \" ... Old is suddenly in \" ( Line 1 , ...</td>\n",
       "      <td>[[America, has, suddenly, become, a, nation, o...</td>\n",
       "      <td>[\", _, \"]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>dist q: The author takes Albert Einstein as an...</td>\n",
       "      <td>[[tell, the, fact, that, Einstein, was, well, ...</td>\n",
       "      <td>[a, messy, shop, front]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>dist q: The author takes Albert Einstein as an...</td>\n",
       "      <td>[[tell, the, fact, that, Einstein, was, well, ...</td>\n",
       "      <td>[a, messy, shop, front]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>dist q: The author used wolves as an example t...</td>\n",
       "      <td>[[explain, the, cruel, side, of, group, -, liv...</td>\n",
       "      <td>[wolves, as, a, model, for, developing, and, m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>dist q: The author used wolves as an example t...</td>\n",
       "      <td>[[explain, the, cruel, side, of, group, -, liv...</td>\n",
       "      <td>[wolves, as, a, model, for, developing, and, m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>dist q: If you are interested in history you w...</td>\n",
       "      <td>[[Rocky, Mountain, National, Park], [Black, Ca...</td>\n",
       "      <td>[Rocky, Mountain, National, Park]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>dist q: If you are interested in history you w...</td>\n",
       "      <td>[[Rocky, Mountain, National, Park], [Black, Ca...</td>\n",
       "      <td>[Rocky, Mountain, National, Park]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>dist q: A girl who likes yoga will go to a: Pe...</td>\n",
       "      <td>[[Camp, Jano, India], [Bay, Language, Academy]]</td>\n",
       "      <td>[Camp, Jano, India]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>dist q: The time of the recognition span can b...</td>\n",
       "      <td>[[one, 's, purpose, in, reading], [lighting, a...</td>\n",
       "      <td>[lighting, and, tiredness]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>dist q: According tothe study by the World Ban...</td>\n",
       "      <td>[[benefit, to, a, third, of, their, population...</td>\n",
       "      <td>[a, third, of, their, population]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     dist q: \" ... Old is suddenly in \" ( Line 1 , ...   \n",
       "3715  dist q: The author takes Albert Einstein as an...   \n",
       "3716  dist q: The author takes Albert Einstein as an...   \n",
       "3738  dist q: The author used wolves as an example t...   \n",
       "3739  dist q: The author used wolves as an example t...   \n",
       "...                                                 ...   \n",
       "1981  dist q: If you are interested in history you w...   \n",
       "1982  dist q: If you are interested in history you w...   \n",
       "93    dist q: A girl who likes yoga will go to a: Pe...   \n",
       "5075  dist q: The time of the recognition span can b...   \n",
       "756   dist q: According tothe study by the World Ban...   \n",
       "\n",
       "                                            Actual Text  \\\n",
       "0     [[America, has, suddenly, become, a, nation, o...   \n",
       "3715  [[tell, the, fact, that, Einstein, was, well, ...   \n",
       "3716  [[tell, the, fact, that, Einstein, was, well, ...   \n",
       "3738  [[explain, the, cruel, side, of, group, -, liv...   \n",
       "3739  [[explain, the, cruel, side, of, group, -, liv...   \n",
       "...                                                 ...   \n",
       "1981  [[Rocky, Mountain, National, Park], [Black, Ca...   \n",
       "1982  [[Rocky, Mountain, National, Park], [Black, Ca...   \n",
       "93      [[Camp, Jano, India], [Bay, Language, Academy]]   \n",
       "5075  [[one, 's, purpose, in, reading], [lighting, a...   \n",
       "756   [[benefit, to, a, third, of, their, population...   \n",
       "\n",
       "                                         Generated Text  bleu  \n",
       "0                                             [\", _, \"]   0.0  \n",
       "3715                            [a, messy, shop, front]   0.0  \n",
       "3716                            [a, messy, shop, front]   0.0  \n",
       "3738  [wolves, as, a, model, for, developing, and, m...   0.0  \n",
       "3739  [wolves, as, a, model, for, developing, and, m...   0.0  \n",
       "...                                                 ...   ...  \n",
       "1981                  [Rocky, Mountain, National, Park]   1.0  \n",
       "1982                  [Rocky, Mountain, National, Park]   1.0  \n",
       "93                                  [Camp, Jano, India]   1.0  \n",
       "5075                         [lighting, and, tiredness]   1.0  \n",
       "756                   [a, third, of, their, population]   1.0  \n",
       "\n",
       "[7500 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.sort_values('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5eef5019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>dist q: What would be the best title for the p...</td>\n",
       "      <td>[[Music, of, the, Mission, District], [The, Sp...</td>\n",
       "      <td>[The, Mission, District]</td>\n",
       "      <td>0.513417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>dist q: The research program is chiefly design...</td>\n",
       "      <td>[[high, school, advisers, from, Houston], [col...</td>\n",
       "      <td>[high, school, students]</td>\n",
       "      <td>0.513417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>dist q: We can judge from the Deloitte study t...</td>\n",
       "      <td>[[the, French, are, less, willing, to, buy, ec...</td>\n",
       "      <td>[French, holiday, shoppers, are, choosing, mor...</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>dist q: From the passage we can see that a: 99...</td>\n",
       "      <td>[[in, Europe, 94, billion, cubic, meters, of, ...</td>\n",
       "      <td>[94, billion, cubic, meters, of, methane, per,...</td>\n",
       "      <td>0.530714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>dist q: As a result of the ticketing mistake ,...</td>\n",
       "      <td>[[will, not, enjoy, the, synchronized, swimmin...</td>\n",
       "      <td>[the, men's, 100, m, final]</td>\n",
       "      <td>0.536256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>dist q: We can find the introduction to a prod...</td>\n",
       "      <td>[[Part, 1], [Part, 2], [Part, 3]]</td>\n",
       "      <td>[Part, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>dist q: What did Paul have for dinner ? a: The...</td>\n",
       "      <td>[[The, soup, and, the, duck], [The, duck, ,, t...</td>\n",
       "      <td>[The, duck, and, the, soup]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>dist q: What does Sue like ? a: Playing games ...</td>\n",
       "      <td>[[Swimming, and, reading]]</td>\n",
       "      <td>[Swimming, and, reading]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>dist q: Lisa in this passage is the name of a:...</td>\n",
       "      <td>[[a, male, lion], [a, pride]]</td>\n",
       "      <td>[a, male, lion]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>dist q: You should especially protect yourself...</td>\n",
       "      <td>[[Jet, Ski, Tours, of, Miami], [15, thStreet, ...</td>\n",
       "      <td>[Jet, Ski, Tours, of, Miami]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "3236  dist q: What would be the best title for the p...   \n",
       "2416  dist q: The research program is chiefly design...   \n",
       "2869  dist q: We can judge from the Deloitte study t...   \n",
       "778   dist q: From the passage we can see that a: 99...   \n",
       "445   dist q: As a result of the ticketing mistake ,...   \n",
       "...                                                 ...   \n",
       "2813  dist q: We can find the introduction to a prod...   \n",
       "3069  dist q: What did Paul have for dinner ? a: The...   \n",
       "3096  dist q: What does Sue like ? a: Playing games ...   \n",
       "1368  dist q: Lisa in this passage is the name of a:...   \n",
       "3751  dist q: You should especially protect yourself...   \n",
       "\n",
       "                                            Actual Text  \\\n",
       "3236  [[Music, of, the, Mission, District], [The, Sp...   \n",
       "2416  [[high, school, advisers, from, Houston], [col...   \n",
       "2869  [[the, French, are, less, willing, to, buy, ec...   \n",
       "778   [[in, Europe, 94, billion, cubic, meters, of, ...   \n",
       "445   [[will, not, enjoy, the, synchronized, swimmin...   \n",
       "...                                                 ...   \n",
       "2813                  [[Part, 1], [Part, 2], [Part, 3]]   \n",
       "3069  [[The, soup, and, the, duck], [The, duck, ,, t...   \n",
       "3096                         [[Swimming, and, reading]]   \n",
       "1368                      [[a, male, lion], [a, pride]]   \n",
       "3751  [[Jet, Ski, Tours, of, Miami], [15, thStreet, ...   \n",
       "\n",
       "                                         Generated Text      bleu  \n",
       "3236                           [The, Mission, District]  0.513417  \n",
       "2416                           [high, school, students]  0.513417  \n",
       "2869  [French, holiday, shoppers, are, choosing, mor...  0.526316  \n",
       "778   [94, billion, cubic, meters, of, methane, per,...  0.530714  \n",
       "445                         [the, men's, 100, m, final]  0.536256  \n",
       "...                                                 ...       ...  \n",
       "2813                                          [Part, 3]  1.000000  \n",
       "3069                        [The, duck, and, the, soup]  1.000000  \n",
       "3096                           [Swimming, and, reading]  1.000000  \n",
       "1368                                    [a, male, lion]  1.000000  \n",
       "3751                       [Jet, Ski, Tours, of, Miami]  1.000000  \n",
       "\n",
       "[312 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare[dist_compare.bleu>0.5].sort_values('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de4a6eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              dist q: We can judge from the Deloitte study t...\n",
       "Actual Text       [[the, French, are, less, willing, to, buy, ec...\n",
       "Generated Text    [French, holiday, shoppers, are, choosing, mor...\n",
       "bleu                                                       0.526316\n",
       "Name: 2869, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[2869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e74f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dist q: We can judge from the Deloitte study that a: over a quarter of the French give second - hand Christmas gifts p: A used book or nearly - new kitchen gadget    may not be at the top of every Christmas wish list , but hard economic times coupled with a new green awareness are changing attitudes about gift - giving in France . French holiday shoppers are choosing larger numbers for \" green \" gifting this Christmas , studies show . About 30 percent of French consumers will give second - hand items as gifts to stretch out their tight budgets but also to do their little bit for recycling , according to a study by international consulting firm Deloitte . The survey of Christmas consumer behaviors in 18 European countries found the French were more than twice as likely as other Europeans to give second - hand items . Websites promoting re - gifting and green gifting are popular in France , with many reporting a rise in business . \" Concerns about the ecology and the economy have come together and we are now seeing people who accept the types of gifts that were not appreciated just a short time ago , \" said Sebastien Ravut , who runs a website promoting eco - friendly consumerism . His site lists shops in France that offer fair trade products , bio - friendly goods and recycled items . Over the Christmas holidays , the number of visits to the site has doubled from last year , reaching 60,000 a month . A study by online survey firm Vivodi for PriceMinister showed eight out of 10 people would be happy to receive a used item as a gift and that younger consumers were more open to the idea . But Gilles Goldenberg , author of the Deloitte study , said that environmental concerns are not why customers buy used goods . \" The number one concern is getting the lowest possible price , \" said Goldenberg . \" Eco - friendly products are drawing a lot of interest , but not if that means paying more . \" Theatre tickets and other low - carbon gifts are fashionable , and eco - friendly websites are also encouraging gift givers to offer time and services instead of stuff . \" The order of the day is to spend less time shopping and more time connecting \" over the holidays , said Florence de Monclin from the Nicolas Helot foundation for Nature and Humanity .'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[2869]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4faf8c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'French',\n",
       "  'are',\n",
       "  'less',\n",
       "  'willing',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'eco',\n",
       "  '-',\n",
       "  'friendly',\n",
       "  'gifts',\n",
       "  'than',\n",
       "  'other',\n",
       "  'Europeans'],\n",
       " ['80',\n",
       "  '%',\n",
       "  'of',\n",
       "  'French',\n",
       "  'people',\n",
       "  'are',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'receive',\n",
       "  'second',\n",
       "  '-',\n",
       "  'hand',\n",
       "  'gifts'],\n",
       " ['less',\n",
       "  'than',\n",
       "  '10',\n",
       "  '%',\n",
       "  'of',\n",
       "  'European',\n",
       "  'consumers',\n",
       "  'are',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'give',\n",
       "  'second',\n",
       "  '-',\n",
       "  'hand',\n",
       "  'gifts']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[2869]['Actual Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a24a7dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French',\n",
       " 'holiday',\n",
       " 'shoppers',\n",
       " 'are',\n",
       " 'choosing',\n",
       " 'more',\n",
       " 'than',\n",
       " 'a',\n",
       " 'quarter',\n",
       " 'of',\n",
       " 'the',\n",
       " 'French',\n",
       " 'consumers',\n",
       " 'will',\n",
       " 'give',\n",
       " 'second',\n",
       " '-',\n",
       " 'hand',\n",
       " 'items']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[2869]['Generated Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c0f2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                      'The quick brown dog jumps on the log.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50a5016b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765),\n",
       " 'rougeL': Score(precision=0.625, recall=0.5555555555555556, fmeasure=0.5882352941176471)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0978308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dist q: You should especially protect yourself from sun burnt while visiting a: American Watersports p: American Watersports     Tuesday - Saturday Located on the beach of the Sea Gardens Beach Resort , there are fun things to rent for the whole family . They offer rentals for kayaks , jet skis , and even parasail ! Enjoy the water up - close or from a bird 's eye view ! No matter what activity you 're enjoying , be sure to protect yourself and your family from the sun 's powerful rays and apply plenty of sun block ! 15thStreet Boat Company Monday - Saturday 15thStreet Boat Company offers rental boats of all kinds . They 're sure to have what you are looking for , whether it 's a small boat for a quick and simple outing or an extravagant boat with comfortable seats with a stereo and high tech navigation . You can rent a boat for half a day or a couple of days , or even weeks at a time . If you want it , they 've got it . It 's fun for everyone ! Coconut 's Watersports      9am-5pm Monday through Sunday Coconut 's Watersports is open 7 days a week for your convenience and offers tons of water fun for the whole family . Jet Ski activities last 30 minutes or 1 hour and can make stops along the way . You must be at least 14 years of age to ride alone and can be as young as 3 to ride along with an adult . Everybody is required to wear a life jacket and a license is required to operate the Jet Ski . Bathing suits and shorts are recommended . Jet Ski Tours of Miami      Thursday - Sunday 10am-7pm Jet Ski Tours of Miami includes onsite parking , indoor restrooms , lockers , and life jackets for participants . You may choose a one or two tour and each Jet Ski can hold up to 3 people . You must be at least 18 years old in order to ride . As long as you are accompanied by an adult , there is no age limitation for any passenger . There is a restaurant nearby to eat at . The tour visits 6 different islands and passes by Bayside and Hard Rock . You may even catch a glimpse of dolphins or a manatee resting in these fabulous Florida waters .\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[3751].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be4b5a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>dist q: The Dixie PIT program was introduced i...</td>\n",
       "      <td>[raise money for school affairs, supply teache...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>dist q: Which of the following sentences from ...</td>\n",
       "      <td>[In her calm , motherly voice she said,\"By the...</td>\n",
       "      <td>''</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dist q: A \" property \" in Australia is a a: fa...</td>\n",
       "      <td>[school]</td>\n",
       "      <td>farm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>dist q: If you want to be a member of Summer S...</td>\n",
       "      <td>[visit Black Rock Forest first]</td>\n",
       "      <td>8455344517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>dist q: What is the best title for the text ? ...</td>\n",
       "      <td>[Put the glass down]</td>\n",
       "      <td>\"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>dist q: According to the author , which of the...</td>\n",
       "      <td>[Western women, Chinese men]</td>\n",
       "      <td>Western women</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>dist q: You should especially protect yourself...</td>\n",
       "      <td>[Jet Ski Tours of Miami, 15 \\n thStreet Boat C...</td>\n",
       "      <td>Jet Ski Tours of Miami</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>dist q: The old woman wants to see a: Xiao Min...</td>\n",
       "      <td>[Xiao Ming]</td>\n",
       "      <td>Xiao Ming</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>dist q: What is the best title for the passage...</td>\n",
       "      <td>[Pop music, Classical music, Folk music]</td>\n",
       "      <td>Classical music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>dist q: Which can be the best title of this pa...</td>\n",
       "      <td>[How to Live Simply, My Grandparents]</td>\n",
       "      <td>My Grandparents</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3773 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1701  dist q: The Dixie PIT program was introduced i...   \n",
       "3554  dist q: Which of the following sentences from ...   \n",
       "37    dist q: A \" property \" in Australia is a a: fa...   \n",
       "1026  dist q: If you want to be a member of Summer S...   \n",
       "3155  dist q: What is the best title for the text ? ...   \n",
       "...                                                 ...   \n",
       "152   dist q: According to the author , which of the...   \n",
       "3751  dist q: You should especially protect yourself...   \n",
       "2218  dist q: The old woman wants to see a: Xiao Min...   \n",
       "3147  dist q: What is the best title for the passage...   \n",
       "3416  dist q: Which can be the best title of this pa...   \n",
       "\n",
       "                                            Actual Text  \\\n",
       "1701  [raise money for school affairs, supply teache...   \n",
       "3554  [In her calm , motherly voice she said,\"By the...   \n",
       "37                                             [school]   \n",
       "1026                    [visit Black Rock Forest first]   \n",
       "3155                               [Put the glass down]   \n",
       "...                                                 ...   \n",
       "152                        [Western women, Chinese men]   \n",
       "3751  [Jet Ski Tours of Miami, 15 \\n thStreet Boat C...   \n",
       "2218                                        [Xiao Ming]   \n",
       "3147           [Pop music, Classical music, Folk music]   \n",
       "3416              [How to Live Simply, My Grandparents]   \n",
       "\n",
       "              Generated Text  bleu  \n",
       "1701                       .   0.0  \n",
       "3554                      ''   0.0  \n",
       "37                      farm   0.0  \n",
       "1026              8455344517   0.0  \n",
       "3155                       \"   0.0  \n",
       "...                      ...   ...  \n",
       "152            Western women   1.0  \n",
       "3751  Jet Ski Tours of Miami   1.0  \n",
       "2218               Xiao Ming   1.0  \n",
       "3147         Classical music   1.0  \n",
       "3416         My Grandparents   1.0  \n",
       "\n",
       "[3773 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.sort_values('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a795529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your eyes are poor',\n",
       " 'your left eye is not open',\n",
       " 'you move it close to your eye']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[675,:]['Actual Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb61db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dist q: You fail to see the letter L in the experiment because a: its image falls on the blind spot p: It seems to be strange to you there is a blind spot on the eyes , Here is an interesting experiment that can make something disappear , when one eye is open . Make a card about the size of a postcard and write two English letters L and R on it , L on the left and R on the right . First , hold the card about 80 cm away and you see both the letters . Then close your right eye and look at the letter R only with your left eye . And now , as you move the card slowly towards you , you'll find the letter L disappearing . But if you move the card nearer to your face , the letter will be seen again . Now do the same experiment with your left eye closed , you'll find the letter R disappearing . Why does the letter disappear ? It is because there is a blind spot on the eye . When the image of the letter falls on the blind spot , it wo n't be seen . That is why either of the letters disappears .\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_compare.iloc[675,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71f6f0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/cluster/home/fgonzalez/.virtualenvs/nlp/lib64/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dist_compare=val.merge(gen_dist,on=['text'])\n",
    "aa=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 1, 0, 0)),axis=1)\n",
    "dist_compare=dist_compare.assign(bleu=aa)\n",
    "#dist_compare=dist_compare.assign(bleu=dist_compare.apply(lambda x:sentence_bleu(x['Actual Text'],x['Generated Text'],weights=(0, 0, 1, 0)),axis=1))\n",
    "bleu_3=dist_compare.bleu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "226874f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.206983827137286e-308"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2c06d",
   "metadata": {},
   "source": [
    "## scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddaf608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21606667354214598"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ea36bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07887480099137983"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9660b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04384669033424478"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b01b244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033407103702946084"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df97e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(Configuration.parse_cmd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
